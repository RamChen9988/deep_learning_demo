"""
è¿ç§»å­¦ä¹ å®æˆ˜ï¼šç«™åœ¨å·¨äººè‚©ä¸Š
ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹å¿«é€Ÿæ„å»ºçŒ«ç‹—åˆ†ç±»å™¨

æ ¸å¿ƒæ€æƒ³ï¼š
1. åˆ©ç”¨åœ¨å¤§æ•°æ®é›†(ImageNet)ä¸Šè®­ç»ƒå¥½çš„æ¨¡å‹
2. å¤ç”¨å…¶ç‰¹å¾æå–èƒ½åŠ›
3. åªè®­ç»ƒæœ€åçš„åˆ†ç±»å±‚ï¼Œé€‚é…æˆ‘ä»¬çš„ä»»åŠ¡

ä¼˜åŠ¿ï¼š
â€¢ è®­ç»ƒé€Ÿåº¦å¿«
â€¢ æ‰€éœ€æ•°æ®å°‘
â€¢ å‡†ç¡®ç‡é«˜
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision
import torchvision.transforms as transforms
import torchvision.models as models
import matplotlib.pyplot as plt
import time
import os
from torchvision.datasets import ImageFolder    

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.family'] = ['SimHei', 'DejaVu Sans', 'Arial']
plt.rcParams['axes.unicode_minus'] = False

class TransferLearningDemo:
    def __init__(self):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        
    def setup_data(self):
        """
        è®¾ç½®æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
        æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨CIFAR-10æ¨¡æ‹ŸçŒ«ç‹—åˆ†ç±»
        å®é™…é¡¹ç›®ä¸­åº”æ›¿æ¢ä¸ºçœŸå®çš„çŒ«ç‹—æ•°æ®é›†
        """
        print("è®¾ç½®æ•°æ®é¢„å¤„ç†...")
        
        # æ•°æ®å¢å¼º - è®­ç»ƒé›†ä½¿ç”¨æ›´å¼ºçš„å¢å¼º
        train_transform = transforms.Compose([
            transforms.Resize(224),  # é¢„è®­ç»ƒæ¨¡å‹éœ€è¦224x224è¾“å…¥
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomRotation(10),
            transforms.ColorJitter(brightness=0.2, contrast=0.2),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNetç»Ÿè®¡ä¿¡æ¯
                               std=[0.229, 0.224, 0.225])
        ])
        
        # æµ‹è¯•é›†ä½¿ç”¨ç®€å•å˜æ¢
        test_transform = transforms.Compose([
            transforms.Resize(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                               std=[0.229, 0.224, 0.225])
        ])
        
        # åŠ è½½CIFAR-10æ•°æ®é›†ï¼ˆæ¨¡æ‹ŸçŒ«ç‹—åˆ†ç±»ï¼‰
        # å®é™…é¡¹ç›®ä¸­åº”è¯¥ä½¿ç”¨ï¼štorchvision.datasets.ImageFolder('path/to/cat_dog_data')
        # å‡è®¾æ•°æ®ç›®å½•ç»“æ„ï¼š
        # data/
        #   train/
        #     cats/
        #     dogs/
        #   test/
        #     cats/ 
        #     dogs/

        # trainset = ImageFolder('data/train', transform=train_transform)
        # testset = ImageFolder('data/test', transform=test_transform)
       

        trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                              download=True, transform=train_transform)
        testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                             download=True, transform=test_transform)
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        self.trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)
        self.testloader = DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)
        
        print(f"è®­ç»ƒæ ·æœ¬æ•°: {len(trainset)}")
        print(f"æµ‹è¯•æ ·æœ¬æ•°: {len(testset)}")
        
        return trainset, testset
    
    def create_transfer_model(self, model_name='resnet18', num_classes=10):
        """
        åˆ›å»ºè¿ç§»å­¦ä¹ æ¨¡å‹
        
        å‚æ•°è¯´æ˜ï¼š
        model_name: é¢„è®­ç»ƒæ¨¡å‹åç§° ('resnet18', 'vgg16', 'alexnet'ç­‰)
        num_classes: æˆ‘ä»¬çš„ä»»åŠ¡ç±»åˆ«æ•°ï¼ˆçŒ«ç‹—åˆ†ç±»æ˜¯2ç±»ï¼‰
        """
        print(f"\nåˆ›å»º {model_name} è¿ç§»å­¦ä¹ æ¨¡å‹...")
        
        # æ–¹æ³•1ï¼šç‰¹å¾æå–ï¼ˆå›ºå®šå·ç§¯å±‚ï¼Œåªè®­ç»ƒåˆ†ç±»å™¨ï¼‰
        def create_feature_extractor():
            """ç‰¹å¾æå–æ–¹æ³• - é€‚åˆå°æ•°æ®é›†"""
            # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
            if model_name == 'resnet18':
                model = models.resnet18(pretrained=True)
            elif model_name == 'vgg16':
                model = models.vgg16(pretrained=True)
            else:
                model = models.alexnet(pretrained=True)
            
            # å†»ç»“æ‰€æœ‰å·ç§¯å±‚å‚æ•° - ä¸æ›´æ–°æƒé‡
            for param in model.parameters():
                param.requires_grad = False
            
            # æ›¿æ¢æœ€åçš„å…¨è¿æ¥å±‚ï¼Œé€‚é…æˆ‘ä»¬çš„ä»»åŠ¡
            if model_name == 'resnet18':
                num_features = model.fc.in_features
                model.fc = nn.Linear(num_features, num_classes)
            elif model_name == 'vgg16':
                num_features = model.classifier[6].in_features
                model.classifier[6] = nn.Linear(num_features, num_classes)
            else:  # alexnet
                num_features = model.classifier[6].in_features
                model.classifier[6] = nn.Linear(num_features, num_classes)
            
            print("ä½¿ç”¨ç‰¹å¾æå–æ–¹æ³•ï¼šå†»ç»“å·ç§¯å±‚ï¼Œåªè®­ç»ƒåˆ†ç±»å™¨")
            return model
        
        # æ–¹æ³•2ï¼šå¾®è°ƒï¼ˆè§£å†»éƒ¨åˆ†å±‚ï¼Œç”¨è¾ƒå°å­¦ä¹ ç‡è®­ç»ƒï¼‰
        def create_fine_tune_model():
            """å¾®è°ƒæ–¹æ³• - é€‚åˆä¸­ç­‰æ•°æ®é›†"""
            # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
            if model_name == 'resnet18':
                model = models.resnet18(pretrained=True)
            elif model_name == 'vgg16':
                model = models.vgg16(pretrained=True)
            else:
                model = models.alexnet(pretrained=True)
            
            # åªå†»ç»“å‰é¢çš„å±‚ï¼Œè§£å†»åé¢çš„å±‚
            if model_name == 'resnet18':
                # å†»ç»“å‰é¢çš„å±‚
                for param in list(model.parameters())[:-20]:  # åªä¿ç•™æœ€å20å±‚å¯è®­ç»ƒ
                    param.requires_grad = False
                # æ›¿æ¢æœ€åçš„å…¨è¿æ¥å±‚
                num_features = model.fc.in_features
                model.fc = nn.Linear(num_features, num_classes)
            elif model_name == 'vgg16':
                # å†»ç»“ç‰¹å¾æå–éƒ¨åˆ†
                for param in model.features.parameters():
                    param.requires_grad = False
                # æ›¿æ¢åˆ†ç±»å™¨
                num_features = model.classifier[6].in_features
                model.classifier[6] = nn.Linear(num_features, num_classes)
            
            print("ä½¿ç”¨å¾®è°ƒæ–¹æ³•ï¼šè§£å†»éƒ¨åˆ†å±‚ï¼Œç”¨è¾ƒå°å­¦ä¹ ç‡è®­ç»ƒ")
            return model
        
        # é€‰æ‹©è¿ç§»å­¦ä¹ æ–¹æ³•
        # æ–¹æ³•1é€‚åˆå°æ•°æ®é›†(<1000æ ·æœ¬)ï¼Œæ–¹æ³•2é€‚åˆä¸­ç­‰æ•°æ®é›†(1000-10000æ ·æœ¬)
        if len(self.trainloader.dataset) < 1000:
            model = create_feature_extractor()
        else:
            model = create_fine_tune_model()
        
        # ç§»åŠ¨åˆ°è®¾å¤‡
        model = model.to(self.device)
        
        # æ‰“å°å¯è®­ç»ƒå‚æ•°æ•°é‡
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        total_params = sum(p.numel() for p in model.parameters())
        print(f"æ€»å‚æ•°: {total_params:,}, å¯è®­ç»ƒå‚æ•°: {trainable_params:,} "
              f"({trainable_params/total_params*100:.1f}%)")
        
        return model
    
    def train_model(self, model, epochs=5):
        """
        è®­ç»ƒè¿ç§»å­¦ä¹ æ¨¡å‹
        """
        print("\nå¼€å§‹è®­ç»ƒè¿ç§»å­¦ä¹ æ¨¡å‹...")
        
        # å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
        criterion = nn.CrossEntropyLoss()
        
        # åªå¯¹éœ€è¦æ¢¯åº¦çš„å‚æ•°è¿›è¡Œä¼˜åŒ–
        optimizer = optim.Adam(
            filter(lambda p: p.requires_grad, model.parameters()),
            lr=0.001,  # è¿ç§»å­¦ä¹ ä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡
            weight_decay=1e-4
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)
        
        train_losses = []
        test_accuracies = []
        
        for epoch in range(epochs):
            # è®­ç»ƒé˜¶æ®µ
            model.train()
            running_loss = 0.0
            correct = 0
            total = 0
            
            start_time = time.time()
            
            for batch_idx, (inputs, targets) in enumerate(self.trainloader):
                inputs, targets = inputs.to(self.device), targets.to(self.device)
                
                # å‰å‘ä¼ æ’­
                optimizer.zero_grad()
                outputs = model(inputs)
                loss = criterion(outputs, targets)
                
                # åå‘ä¼ æ’­
                loss.backward()
                optimizer.step()
                
                # ç»Ÿè®¡ä¿¡æ¯
                running_loss += loss.item()
                _, predicted = outputs.max(1)
                total += targets.size(0)
                correct += predicted.eq(targets).sum().item()
                
                if batch_idx % 100 == 99:
                    print(f'Batch {batch_idx+1}, Loss: {running_loss/100:.3f}')
                    running_loss = 0.0
            
            # å­¦ä¹ ç‡è°ƒåº¦
            scheduler.step()
            
            # æµ‹è¯•å‡†ç¡®ç‡
            test_acc = self.evaluate_model(model)
            
            train_losses.append(running_loss / len(self.trainloader))
            test_accuracies.append(test_acc)
            
            epoch_time = time.time() - start_time
            print(f'Epoch {epoch+1}/{epochs}, æ—¶é—´: {epoch_time:.1f}s, '
                  f'æµ‹è¯•å‡†ç¡®ç‡: {test_acc:.2f}%')
        
        return train_losses, test_accuracies
    
    def evaluate_model(self, model):
        """
        è¯„ä¼°æ¨¡å‹æ€§èƒ½
        """
        model.eval()
        correct = 0
        total = 0
        
        with torch.no_grad():
            for inputs, targets in self.testloader:
                inputs, targets = inputs.to(self.device), targets.to(self.device)
                outputs = model(inputs)
                _, predicted = outputs.max(1)
                total += targets.size(0)
                correct += predicted.eq(targets).sum().item()
        
        accuracy = 100. * correct / total
        return accuracy
    
    def compare_strategies(self):
        """
        æ¯”è¾ƒä¸åŒè¿ç§»å­¦ä¹ ç­–ç•¥çš„æ•ˆæœ
        """
        print("\næ¯”è¾ƒä¸åŒè¿ç§»å­¦ä¹ ç­–ç•¥...")
        
        strategies = {
            'ç‰¹å¾æå–(å†»ç»“æ‰€æœ‰)': self.create_transfer_model(),
            'å¾®è°ƒ(è§£å†»éƒ¨åˆ†)': self.create_fine_tune_model()
        }
        
        results = {}
        
        for name, model in strategies.items():
            print(f"\nè®­ç»ƒç­–ç•¥: {name}")
            train_losses, test_accuracies = self.train_model(model, epochs=3)
            final_acc = test_accuracies[-1]
            results[name] = final_acc
            print(f"{name} æœ€ç»ˆå‡†ç¡®ç‡: {final_acc:.2f}%")
        
        # å¯è§†åŒ–æ¯”è¾ƒç»“æœ
        self.visualize_comparison(results)
        
        return results
    
    def create_fine_tune_model(self):
        """åˆ›å»ºå¾®è°ƒæ¨¡å‹ç¤ºä¾‹"""
        model = models.resnet18(pretrained=True)
        
        # è§£å†»æœ€å2ä¸ªå·ç§¯å—
        for name, param in model.named_parameters():
            if 'layer4' in name or 'layer3' in name:  # è§£å†»åé¢çš„å±‚
                param.requires_grad = True
            else:  # å†»ç»“å‰é¢çš„å±‚
                param.requires_grad = False
        
        # æ›¿æ¢åˆ†ç±»å™¨
        num_features = model.fc.in_features
        model.fc = nn.Linear(num_features, 10)
        
        return model.to(self.device)
    
    def visualize_comparison(self, results):
        """
        å¯è§†åŒ–è¿ç§»å­¦ä¹ æ•ˆæœå¯¹æ¯”
        """
        strategies = list(results.keys())
        accuracies = list(results.values())
        
        plt.figure(figsize=(10, 6))
        bars = plt.bar(strategies, accuracies, color=['skyblue', 'lightgreen'])
        
        plt.title('è¿ç§»å­¦ä¹ ç­–ç•¥æ•ˆæœå¯¹æ¯”', fontsize=14, fontweight='bold')
        plt.ylabel('æµ‹è¯•å‡†ç¡®ç‡ (%)', fontsize=12)
        plt.ylim(0, 100)
        plt.grid(True, alpha=0.3, axis='y')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, acc in zip(bars, accuracies):
            height = bar.get_height()
            plt.text(bar.get_x() + bar.get_width()/2, height + 0.5,
                    f'{acc:.1f}%', ha='center', va='bottom', fontweight='bold')
        
        plt.tight_layout()
        plt.show()
    
    def run_demo(self):
        """
        è¿è¡Œå®Œæ•´çš„è¿ç§»å­¦ä¹ æ¼”ç¤º
        """
        print("=" * 60)
        print("è¿ç§»å­¦ä¹ å®æˆ˜æ¼”ç¤º")
        print("ç›®æ ‡: ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹å¿«é€Ÿæ„å»ºå›¾åƒåˆ†ç±»å™¨")
        print("=" * 60)
        
        # 1. è®¾ç½®æ•°æ®
        self.setup_data()
        
        # 2. åˆ›å»ºè¿ç§»å­¦ä¹ æ¨¡å‹
        model = self.create_transfer_model('resnet18', 10)
        # ä¿®æ”¹æ¨¡å‹è¾“å‡ºç±»åˆ«æ•°
        #model = self.create_transfer_model('resnet18', num_classes=2)  # çŒ«ç‹—æ˜¯2åˆ†ç±»

        
        # 3. è®­ç»ƒæ¨¡å‹
        print("\nå¼€å§‹è®­ç»ƒ...")
        train_losses, test_accuracies = self.train_model(model, epochs=5)
        
        # 4. æœ€ç»ˆè¯„ä¼°
        final_accuracy = self.evaluate_model(model)
        print(f"\nğŸ‰ è¿ç§»å­¦ä¹ æ¨¡å‹æœ€ç»ˆå‡†ç¡®ç‡: {final_accuracy:.2f}%")
        
        # 5. æ¯”è¾ƒä¸åŒç­–ç•¥
        print("\n" + "="*50)
        print("ç­–ç•¥æ¯”è¾ƒ")
        print("="*50)
        self.compare_strategies()
        
        # 6. ä¿å­˜æ¨¡å‹
        torch.save(model.state_dict(), 'transfer_learning_model.pth')
        print("\nğŸ’¾ æ¨¡å‹å·²ä¿å­˜ä¸º 'transfer_learning_model.pth'")
        
        # 7. ä½¿ç”¨å»ºè®®
        print("\nğŸ’¡ è¿ç§»å­¦ä¹ ä½¿ç”¨å»ºè®®:")
        print("â€¢ å°æ•°æ®é›†(<1000æ ·æœ¬): ä½¿ç”¨ç‰¹å¾æå–æ–¹æ³•")
        print("â€¢ ä¸­ç­‰æ•°æ®é›†(1000-10000æ ·æœ¬): ä½¿ç”¨å¾®è°ƒæ–¹æ³•") 
        print("â€¢ å¤§æ•°æ®é›†(>10000æ ·æœ¬): å¯ä»¥è€ƒè™‘ä»å¤´è®­ç»ƒ")
        print("â€¢ ç›¸ä¼¼ä»»åŠ¡: ä½¿ç”¨ç‰¹å¾æå–")
        print("â€¢ ä¸åŒä»»åŠ¡: ä½¿ç”¨å¾®è°ƒ")

def main():
    """ä¸»å‡½æ•°"""
    demo = TransferLearningDemo()
    demo.run_demo()

if __name__ == "__main__":
    main()