"""
ç®€åŒ–ç‰ˆè¿ç§»å­¦ä¹ ç¨‹åº
åŸºäºé¢„è®­ç»ƒæ¨¡å‹å¿«é€Ÿæ„å»ºå›¾åƒåˆ†ç±»å™¨
åªä½¿ç”¨æœ€ä¼˜çš„å¾®è°ƒæ–¹æ³•ï¼Œç§»é™¤ç­–ç•¥æ¯”è¾ƒ
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision.transforms as transforms
import torchvision.models as models
import matplotlib.pyplot as plt
import time
import os
from torchvision.datasets import ImageFolder

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.family'] = ['SimHei', 'DejaVu Sans', 'Arial']
plt.rcParams['axes.unicode_minus'] = False

class SimpleTransferLearning:
    def __init__(self):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        
    def setup_data(self, data_dir='../data/'):
        """
        è®¾ç½®æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
        """
        print("è®¾ç½®æ•°æ®é¢„å¤„ç†...")
        
        # æ•°æ®å¢å¼º - è®­ç»ƒé›†ä½¿ç”¨æ›´å¼ºçš„å¢å¼º
        train_transform = transforms.Compose([
            transforms.Resize((224, 224)),  # é¢„è®­ç»ƒæ¨¡å‹éœ€è¦224x224è¾“å…¥
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomRotation(10),
            transforms.ColorJitter(brightness=0.2, contrast=0.2),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNetç»Ÿè®¡ä¿¡æ¯
                               std=[0.229, 0.224, 0.225])
        ])
        
        # æµ‹è¯•é›†ä½¿ç”¨ç®€å•å˜æ¢
        test_transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                               std=[0.229, 0.224, 0.225])
        ])
        
        # åŠ è½½æ•°æ®é›†
        train_dir = os.path.join(data_dir, 'train')
        test_dir = os.path.join(data_dir, 'test')
        
        trainset = ImageFolder(train_dir, transform=train_transform)
        testset = ImageFolder(test_dir, transform=test_transform)
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        self.trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)
        self.testloader = DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)
        
        print(f"è®­ç»ƒæ ·æœ¬æ•°: {len(trainset)}")
        print(f"æµ‹è¯•æ ·æœ¬æ•°: {len(testset)}")
        print(f"ç±»åˆ«: {trainset.classes}")
        
        return trainset, testset
    
    def create_model(self, model_name='resnet18'):
        """
        åˆ›å»ºè¿ç§»å­¦ä¹ æ¨¡å‹ - ä½¿ç”¨æœ€ä¼˜çš„å¾®è°ƒæ–¹æ³•
        """
        print(f"\nåˆ›å»º {model_name} è¿ç§»å­¦ä¹ æ¨¡å‹...")
        
        # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆä½¿ç”¨æœ€æ–°çš„weights APIï¼‰
        if model_name == 'resnet18':
            model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)
        elif model_name == 'vgg16':
            model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)
        else:
            model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)  # é»˜è®¤ä½¿ç”¨resnet18
        
        # å¾®è°ƒæ–¹æ³•ï¼šè§£å†»éƒ¨åˆ†å±‚
        if model_name == 'resnet18':
            # è§£å†»æœ€å2ä¸ªå·ç§¯å—
            for name, param in model.named_parameters():
                if 'layer4' in name or 'layer3' in name:  # è§£å†»åé¢çš„å±‚
                    param.requires_grad = True
                else:  # å†»ç»“å‰é¢çš„å±‚
                    param.requires_grad = False
            # æ›¿æ¢åˆ†ç±»å™¨
            num_features = model.fc.in_features
            model.fc = nn.Linear(num_features, len(self.trainloader.dataset.classes))
        elif model_name == 'vgg16':
            # å†»ç»“ç‰¹å¾æå–éƒ¨åˆ†
            for param in model.features.parameters():
                param.requires_grad = False
            # æ›¿æ¢åˆ†ç±»å™¨
            num_features = model.classifier[6].in_features
            model.classifier[6] = nn.Linear(num_features, len(self.trainloader.dataset.classes))
        
        # ç§»åŠ¨åˆ°è®¾å¤‡
        model = model.to(self.device)
        
        # æ‰“å°å¯è®­ç»ƒå‚æ•°æ•°é‡
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        total_params = sum(p.numel() for p in model.parameters())
        print(f"æ€»å‚æ•°: {total_params:,}, å¯è®­ç»ƒå‚æ•°: {trainable_params:,} "
              f"({trainable_params/total_params*100:.1f}%)")
        
        return model
    
    def train_model(self, model, epochs=5):
        """
        è®­ç»ƒè¿ç§»å­¦ä¹ æ¨¡å‹
        """
        print("\nå¼€å§‹è®­ç»ƒè¿ç§»å­¦ä¹ æ¨¡å‹...")
        
        # å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(
            filter(lambda p: p.requires_grad, model.parameters()),
            lr=0.001,  # è¿ç§»å­¦ä¹ ä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡
            weight_decay=1e-4
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)
        
        train_losses = []
        test_accuracies = []
        
        for epoch in range(epochs):
            # è®­ç»ƒé˜¶æ®µ
            model.train()
            running_loss = 0.0
            correct = 0
            total = 0
            
            start_time = time.time()
            
            for batch_idx, (inputs, targets) in enumerate(self.trainloader):
                inputs, targets = inputs.to(self.device), targets.to(self.device)
                
                # å‰å‘ä¼ æ’­
                optimizer.zero_grad()
                outputs = model(inputs)
                loss = criterion(outputs, targets)
                
                # åå‘ä¼ æ’­
                loss.backward()
                optimizer.step()
                
                # ç»Ÿè®¡ä¿¡æ¯
                running_loss += loss.item()
                _, predicted = outputs.max(1)
                total += targets.size(0)
                correct += predicted.eq(targets).sum().item()
                
                if batch_idx % 50 == 49:
                    print(f'Batch {batch_idx+1}, Loss: {running_loss/50:.3f}')
                    running_loss = 0.0
            
            # å­¦ä¹ ç‡è°ƒåº¦
            scheduler.step()
            
            # æµ‹è¯•å‡†ç¡®ç‡
            test_acc = self.evaluate_model(model)
            
            train_losses.append(running_loss / len(self.trainloader))
            test_accuracies.append(test_acc)
            
            epoch_time = time.time() - start_time
            print(f'Epoch {epoch+1}/{epochs}, æ—¶é—´: {epoch_time:.1f}s, '
                  f'è®­ç»ƒå‡†ç¡®ç‡: {100.*correct/total:.2f}%, æµ‹è¯•å‡†ç¡®ç‡: {test_acc:.2f}%')
        
        return train_losses, test_accuracies
    
    def evaluate_model(self, model):
        """
        è¯„ä¼°æ¨¡å‹æ€§èƒ½
        """
        model.eval()
        correct = 0
        total = 0
        
        with torch.no_grad():
            for inputs, targets in self.testloader:
                inputs, targets = inputs.to(self.device), targets.to(self.device)
                outputs = model(inputs)
                _, predicted = outputs.max(1)
                total += targets.size(0)
                correct += predicted.eq(targets).sum().item()
        
        accuracy = 100. * correct / total
        return accuracy
    
    def plot_training_history(self, train_losses, test_accuracies):
        """
        ç»˜åˆ¶è®­ç»ƒå†å²
        """
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
        
        # ç»˜åˆ¶æŸå¤±
        ax1.plot(train_losses, 'b-', linewidth=2)
        ax1.set_title('è®­ç»ƒæŸå¤±', fontsize=14, fontweight='bold')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Loss')
        ax1.grid(True, alpha=0.3)
        
        # ç»˜åˆ¶å‡†ç¡®ç‡
        ax2.plot(test_accuracies, 'g-', linewidth=2, marker='o')
        ax2.set_title('æµ‹è¯•å‡†ç¡®ç‡', fontsize=14, fontweight='bold')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Accuracy (%)')
        ax2.set_ylim(0, 100)
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
    
    def run_demo(self, data_dir='../data/', model_name='resnet18', epochs=5):
        """
        è¿è¡Œç®€åŒ–çš„è¿ç§»å­¦ä¹ æ¼”ç¤º
        """
        print("=" * 50)
        print("ç®€åŒ–ç‰ˆè¿ç§»å­¦ä¹ æ¼”ç¤º")
        print("ç›®æ ‡: ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹å¿«é€Ÿæ„å»ºå›¾åƒåˆ†ç±»å™¨")
        print("=" * 50)
        
        # 1. è®¾ç½®æ•°æ®
        self.setup_data(data_dir)
        
        # 2. åˆ›å»ºè¿ç§»å­¦ä¹ æ¨¡å‹
        model = self.create_model(model_name)
        
        # 3. è®­ç»ƒæ¨¡å‹
        print("\nå¼€å§‹è®­ç»ƒ...")
        train_losses, test_accuracies = self.train_model(model, epochs)
        
        # 4. æœ€ç»ˆè¯„ä¼°
        final_accuracy = self.evaluate_model(model)
        print(f"\nğŸ‰ è¿ç§»å­¦ä¹ æ¨¡å‹æœ€ç»ˆå‡†ç¡®ç‡: {final_accuracy:.2f}%")
        
        # 5. ç»˜åˆ¶è®­ç»ƒå†å²
        self.plot_training_history(train_losses, test_accuracies)
        
        # 6. ä¿å­˜æ¨¡å‹
        model_path = f'../save_model/simple_transfer_learning_{model_name}.pth'
        torch.save(model.state_dict(), model_path)
        print(f"\nğŸ’¾ æ¨¡å‹å·²ä¿å­˜ä¸º '{model_path}'")
        
        return model, final_accuracy

def main():
    """ä¸»å‡½æ•°"""
    demo = SimpleTransferLearning()
    
    # è¿è¡Œæ¼”ç¤º
    model, accuracy = demo.run_demo(
        data_dir='../data/',    # æ•°æ®ç›®å½•
        model_name='resnet18', # é¢„è®­ç»ƒæ¨¡å‹
        epochs=5               # è®­ç»ƒè½®æ•°
    )
    
    print(f"\nâœ… è¿ç§»å­¦ä¹ å®Œæˆ!")
    print(f"æœ€ç»ˆå‡†ç¡®ç‡: {accuracy:.2f}%")

if __name__ == "__main__":
    main()
